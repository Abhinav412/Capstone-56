{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "wandb_api_key = os.getenv(\"wand_api_key\")\n",
    "\n",
    "!wandb login $wandb_api_key\n",
    "wandb.login()\n",
    "\n",
    "run = wandb.init(project='huggingface')\n",
    "artifact = run.use_artifact('finbert-augmented:latest', type=\"model\")\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "artifact_dir = os.getenv(\"artifact_dir\")\n",
    "\n",
    "model_path = f\"{artifact_dir}/finbert.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.8687e-04, 8.2450e-05, 9.9943e-01]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"The stock market is performing exceptionally well today.\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Gensol Engineering shares hit another lower circuit level; drop for 11th day after SEBI curbs', 'source': 'BusinessLine', 'published_at': '2025-04-24T06:11:47Z', 'url': 'https://www.thehindubusinessline.com/markets/stock-markets/gensol-engineering-shares-hit-another-lower-circuit-level-drop-for-11th-day-after-sebi-curbs/article69485650.ece'}\n",
      "{'title': 'Sensex falls! But these stocks are up over 15% on BSE', 'source': 'The Times of India', 'published_at': '2025-04-24T05:56:37Z', 'url': 'https://economictimes.indiatimes.com/markets/stocks/stock-watch/sensex-falls-but-these-stocks-are-up-over-15-on-bse/articleshow/120573654.cms'}\n",
      "{'title': 'Stock market update: Power stocks up as market falls', 'source': 'The Times of India', 'published_at': '2025-04-24T05:51:28Z', 'url': 'https://economictimes.indiatimes.com/markets/stocks/stock-watch/stock-market-update-power-stocks-up-as-market-falls/articleshow/120573535.cms'}\n",
      "{'title': 'Gensol Engineering rejects reports linking promoters to ED probe in Mahadev betting app Case', 'source': 'The Times of India', 'published_at': '2025-04-24T05:50:15Z', 'url': 'https://economictimes.indiatimes.com/industry/renewables/gensol-engineering-rejects-reports-linking-promoters-to-ed-probe-in-mahadev-betting-app-case/articleshow/120573382.cms'}\n",
      "{'title': 'Stock market update: Stocks that hit 52-week highs on NSE', 'source': 'The Times of India', 'published_at': '2025-04-24T05:46:17Z', 'url': 'https://economictimes.indiatimes.com/markets/stocks/stock-watch/stock-market-update-stocks-that-hit-52-week-highs-on-nse/articleshow/120573383.cms'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "class NewsRetrievalAgent:\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://newsapi.org/v2/everything?q=NSE\"\n",
    "\n",
    "    def fetch_news(self, query=\"IPO OR initial public offering\", days=7, sources=None):\n",
    "        date_from = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"from\": date_from,\n",
    "            \"language\": \"en\",\n",
    "            \"sortBy\": \"publishedAt\",\n",
    "            \"apiKey\": self.api_key\n",
    "        }\n",
    "        if sources:\n",
    "            params[\"sources\"] = sources\n",
    "        \n",
    "        response = requests.get(self.base_url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"articles\", [])\n",
    "        else:\n",
    "            print(f\"Error fetching news: {response.status_code}\")\n",
    "            return []\n",
    "\n",
    "    def summarize_news(self, articles, top_n=5):\n",
    "        summaries = []\n",
    "        for article in articles[:top_n]:\n",
    "            summaries.append({\n",
    "                \"title\": article[\"title\"],\n",
    "                \"source\": article[\"source\"][\"name\"],\n",
    "                \"published_at\": article[\"publishedAt\"],\n",
    "                \"url\": article[\"url\"]\n",
    "            })\n",
    "        return summaries\n",
    "\n",
    "news_api_key = os.getenv(\"news_api_key\")\n",
    "news_agent = NewsRetrievalAgent(news_api_key)\n",
    "news_articles = news_agent.fetch_news()\n",
    "summaries = news_agent.summarize_news(news_articles)\n",
    "\n",
    "for news in summaries:\n",
    "    print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gensol Engineering shares hit another lower circuit level; drop for 11th day after SEBI curbs {'negative': 0.9990509152412415, 'neutral': 0.0007546000415459275, 'positive': 0.00019442831398919225}\n",
      "Sensex falls! But these stocks are up over 15% on BSE {'negative': 0.00047348366933874786, 'neutral': 0.02258582040667534, 'positive': 0.9769407510757446}\n",
      "Stock market update: Power stocks up as market falls {'negative': 0.0008851760649122298, 'neutral': 0.9972459077835083, 'positive': 0.0018689731368795037}\n",
      "Gensol Engineering rejects reports linking promoters to ED probe in Mahadev betting app Case {'negative': 0.9792022109031677, 'neutral': 0.020305577665567398, 'positive': 0.0004921953659504652}\n",
      "Stock market update: Stocks that hit 52-week highs on NSE {'negative': 0.0017717990558594465, 'neutral': 0.4831587076187134, 'positive': 0.5150695443153381}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "model_path = f\"{artifact_dir}/finbert.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "def analyze_sentiment(news_articles):\n",
    "    results = []\n",
    "    for article in news_articles:\n",
    "        text = article[\"title\"] + \" \" + article.get(\"description\", \"\")\n",
    "        inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        sentiment = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        article[\"sentiment\"] = {\n",
    "            \"negative\": sentiment[0],\n",
    "            \"neutral\": sentiment[1],\n",
    "            \"positive\": sentiment[2]\n",
    "        }\n",
    "        results.append(article)\n",
    "\n",
    "    return results\n",
    "\n",
    "#news_articles = news_agent.summarize_news(news_articles)\n",
    "news_with_sentiment = analyze_sentiment(summaries)\n",
    "\n",
    "for news in news_with_sentiment:\n",
    "    print(news[\"title\"], news[\"sentiment\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 articles to nse_news_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "artifact_dir = os.getenv(\"artifact_dir\")\n",
    "news_api_key = os.getenv(\"news_api_key\")\n",
    "model_path = f\"{artifact_dir}/finbert.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "NEWS_URL = \"https://newsapi.org/v2/everything\"\n",
    "QUERY = 'NSE OR \"National Stock Exchange of India\"'\n",
    "LANGUAGE = \"en\"\n",
    "\n",
    "def fetch_nse_news():\n",
    "    params = {\n",
    "        \"q\": QUERY,\n",
    "        \"language\": LANGUAGE,\n",
    "        \"apiKey\": news_api_key\n",
    "    }\n",
    "    response = requests.get(NEWS_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"articles\", [])\n",
    "    else:\n",
    "        print(f\"Error fetching news: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def analyze_sentiment(news_articles):\n",
    "    results = []\n",
    "    for article in news_articles:\n",
    "        text = article[\"title\"] + \" \" + article.get(\"description\", \"\")\n",
    "        inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        sentiment = torch.softmax(logits, dim=1)[0].tolist()\n",
    "\n",
    "        total=sum(sentiment)\n",
    "        if total>0:\n",
    "            sentiment=[x/total for x in sentiment]\n",
    "\n",
    "        sentiment = [round(x,4) for x in sentiment]\n",
    "        \n",
    "        article[\"sentiment\"] = {\n",
    "            \"negative\": sentiment[0],\n",
    "            \"neutral\": sentiment[1],\n",
    "            \"positive\": sentiment[2]\n",
    "        }\n",
    "        results.append(article)\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_to_csv(news_with_sentiment, filename=\"nse_news_sentiment.csv\"):\n",
    "    file_exists = os.path.exists(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Date\", \"Title\", \"Source\", \"URL\", \"Positive\", \"Neutral\", \"Negative\"])\n",
    "\n",
    "        for article in news_with_sentiment:\n",
    "            writer.writerow([\n",
    "                datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                article[\"title\"],\n",
    "                article[\"source\"][\"name\"],\n",
    "                article[\"url\"],\n",
    "                article[\"sentiment\"][\"positive\"],\n",
    "                article[\"sentiment\"][\"neutral\"],\n",
    "                article[\"sentiment\"][\"negative\"]\n",
    "            ])\n",
    "    print(f\"Saved {len(news_with_sentiment)} articles to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    news_articles = fetch_nse_news()\n",
    "    if news_articles:\n",
    "        news_with_sentiment = analyze_sentiment(news_articles)\n",
    "        save_to_csv(news_with_sentiment)\n",
    "    else:\n",
    "        print(\"No news articles retrieved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 articles to bse_news_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"ProsusAI/finbert\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "model_path = f\"{artifact_dir}/finbert.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "NEWS_URL = \"https://newsapi.org/v2/everything\"\n",
    "QUERY = 'BSE OR \"Bombay Stock Exchange of India\"'\n",
    "LANGUAGE = \"en\"\n",
    "\n",
    "def fetch_nse_news():\n",
    "    params = {\n",
    "        \"q\": QUERY,\n",
    "        \"language\": LANGUAGE,\n",
    "        \"apiKey\": news_api_key\n",
    "    }\n",
    "    response = requests.get(NEWS_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"articles\", [])\n",
    "    else:\n",
    "        print(f\"Error fetching news: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "def analyze_sentiment(news_articles):\n",
    "    results = []\n",
    "    for article in news_articles:\n",
    "        text = article[\"title\"] + \" \" + article.get(\"description\", \"\")\n",
    "        inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        sentiment = torch.softmax(logits, dim=1)[0].tolist()\n",
    "\n",
    "        total=sum(sentiment)\n",
    "        if total>0:\n",
    "            sentiment=[x/total for x in sentiment]\n",
    "\n",
    "        sentiment = [round(x,4) for x in sentiment]\n",
    "        \n",
    "        article[\"sentiment\"] = {\n",
    "            \"negative\": sentiment[0],\n",
    "            \"neutral\": sentiment[1],\n",
    "            \"positive\": sentiment[2]\n",
    "        }\n",
    "        results.append(article)\n",
    "\n",
    "    return results\n",
    "\n",
    "def save_to_csv(news_with_sentiment, filename=\"bse_news_sentiment.csv\"):\n",
    "    file_exists = os.path.exists(filename)\n",
    "    with open(filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Date\", \"Title\", \"Source\", \"URL\", \"Positive\", \"Neutral\", \"Negative\"])\n",
    "\n",
    "        for article in news_with_sentiment:\n",
    "            writer.writerow([\n",
    "                datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "                article[\"title\"],\n",
    "                article[\"source\"][\"name\"],\n",
    "                article[\"url\"],\n",
    "                article[\"sentiment\"][\"positive\"],\n",
    "                article[\"sentiment\"][\"neutral\"],\n",
    "                article[\"sentiment\"][\"negative\"]\n",
    "            ])\n",
    "    print(f\"Saved {len(news_with_sentiment)} articles to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    news_articles = fetch_nse_news()\n",
    "    if news_articles:\n",
    "        news_with_sentiment = analyze_sentiment(news_articles)\n",
    "        save_to_csv(news_with_sentiment)\n",
    "    else:\n",
    "        print(\"No news articles retrieved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
